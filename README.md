# AI Chat Support (Ollama + Gemma)
- Backend: FastAPI
- Model: Gemma via Ollama
- Frontend: React (سيُجهّز لاحقًا)

## أوامر سريعة
- تشغيل Ollama: `ollama serve`
- سحب موديل: `ollama pull gemma2:2b`
- اختبار: `ollama run gemma2:2b "hello"`
